# Handwritten Notes on Generative AI

This directory contains my personal handwritten notes from various lectures, workshops, and study sessions on Generative AI topics.

## Contents

The notes cover a wide range of topics in the field of Generative AI, including but not limited to:

1. **Fundamentals of Natural Language Processing**
   - Tokenization, embeddings, and language modeling
   - Transformer architecture and attention mechanisms
   - Evaluation metrics for NLP tasks

2. **Large Language Models (LLMs)**
   - Architecture and scaling laws
   - Pre-training and fine-tuning approaches
   - Prompt engineering techniques
   - Limitations and challenges

3. **Retrieval Augmented Generation (RAG)**
   - Vector databases and similarity search
   - Document processing and chunking strategies
   - Retrieval mechanisms and ranking algorithms
   - Integration with LLMs

4. **LLMOps and Deployment**
   - Model serving and optimization
   - Monitoring and evaluation
   - Cost optimization strategies
   - Security and privacy considerations

5. **Multimodal AI Systems**
   - Text-to-image models
   - Text-to-speech synthesis
   - Vision-language models
   - Multimodal embeddings

## Organization

The notes are organized chronologically based on the course progression. Each file is named according to the date and main topic covered in that session.

## Usage

These notes are meant for personal reference and study purposes. They complement the practical implementations found in the `projects_and_implementations` directory.

## Author

Rohit Chigatapu - Computer Science Engineering Student